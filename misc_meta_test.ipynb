{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from numpy import unique\n",
    "from datetime import date, datetime\n",
    "\n",
    "\n",
    "\n",
    "ID_API = \"https://covid19.figshare.com/api/institutions/857/\"\n",
    "FIGSHARE_API = \"https://api.figshare.com/v2/articles/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "#scriptpath = ''\n",
    "script_path = pathlib.Path(__file__).parent.absolute()\n",
    "with open(scriptpath+'append_misc_meta.py','w+') as appendfile:\n",
    "    r = requests.get('https://raw.githubusercontent.com/gtsueng/outbreak_misc_meta/main/append_misc_meta.py')\n",
    "    appendfile.write(r.text)\n",
    "    appendfile.close()\n",
    "\n",
    "from append_misc_meta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFigshare(id_url, api_url, testing=False):\n",
    "    not_complete = True\n",
    "    i = 0\n",
    "    size = 1000\n",
    "    ids = []\n",
    "    # First calls: get the COVID-related IDs\n",
    "    while(not_complete):\n",
    "        new_ids = getIDs(id_url, i * size, size)\n",
    "        if(len(new_ids) == 0):\n",
    "            not_complete = False\n",
    "        else:\n",
    "            print(f\"Fetched IDs {i*size +1} - {(i+1)*size}\")\n",
    "            ids.extend(new_ids)\n",
    "            i += 1\n",
    "    print(\"Finished API call to get COVID-19 ID list\")\n",
    "    # Second call: get the metadata associated with said ID.\n",
    "    # The call to /institutions pulls SOME metadata, but not all (of course.  Why would things be simple?)\n",
    "    if(testing):\n",
    "        ids = ids[0:5]\n",
    "    md = [cleanupFigshare(api_url, id, idx, len(ids))\n",
    "          for idx, id in enumerate(ids)]\n",
    "    unique_ids = len(set([entry[\"_id\"] for entry in md if entry]))\n",
    "    if(unique_ids != len(md)):\n",
    "        print(\"\\nWARNING: IDs are not unique, or some requests returned an error!\")\n",
    "        print(f\"\\n{len(md) - unique_ids} missing or duplicated unique ids\")\n",
    "    print(\"DONE!\")\n",
    "\n",
    "    return(md)\n",
    "\n",
    "def getIDs(id_url, page=0, size=1000):\n",
    "    resp = requests.get(f\"{id_url}items?&page={page}&page_size={size}\")\n",
    "    if resp.status_code == 200:\n",
    "        raw_data = resp.json()\n",
    "        # First call: get the COVID-related IDs\n",
    "        ids = [item[\"data\"][\"id\"] for item in raw_data[\"items\"]]\n",
    "        return(ids)\n",
    "    return []\n",
    "\n",
    "def cleanupFigshare(api_url, id, idx, total):\n",
    "    if(idx % 10 == 0):\n",
    "        print(f\"finished {idx} of {total}\")\n",
    "\n",
    "    resp = requests.get(f\"{api_url}{id}\")\n",
    "    if resp.status_code == 200:\n",
    "        entry = resp.json()\n",
    "        today = date.today().strftime(\"%Y-%m-%d\")\n",
    "        md = {\"curatedBy\": {\"@type\": \"Organization\",\n",
    "                            \"url\": entry[\"figshare_url\"], \"name\": \"Figshare\", \"curationDate\": today}}\n",
    "        md[\"@type\"] = standardizeType(entry[\"defined_type_name\"])\n",
    "        md[\"_id\"] = f'figshare{entry[\"id\"]}'\n",
    "        md[\"identifier\"] = entry[\"id\"]\n",
    "        md[\"doi\"] = entry[\"doi\"]\n",
    "        md[\"name\"] = entry[\"title\"]\n",
    "        md[\"url\"] = entry[\"figshare_url\"]\n",
    "        md[\"description\"] = entry[\"description\"]\n",
    "        md[\"author\"] = [{\"@type\": \"Person\", \"name\": author[\"full_name\"]}\n",
    "                        for author in entry[\"authors\"]]\n",
    "        md[\"funding\"] = [getFunder(grant) for grant in entry[\"funding_list\"]]\n",
    "        md[\"dateModified\"] = standardizeDate(entry[\"timeline\"].get(\"revision\", ''))\n",
    "        md[\"dateCreated\"] = standardizeDate(entry[\"timeline\"][\"firstOnline\"])\n",
    "        md[\"datePublished\"] = standardizeDate(entry[\"timeline\"][\"posted\"])\n",
    "        cats = [category[\"title\"] for category in entry[\"categories\"]]\n",
    "        cats.extend(entry[\"tags\"])\n",
    "        md[\"keywords\"] = list(unique(cats))\n",
    "        md[\"license\"] = entry[\"license\"][\"url\"]\n",
    "        md[\"isBasedOn\"] = [{\"url\": ref} for ref in entry[\"references\"]]\n",
    "        if (\"files\" in entry.keys()):\n",
    "            md[\"distribution\"] = [\n",
    "                {\"name\": fileobj[\"name\"], \"contentUrl\": fileobj[\"download_url\"]} for fileobj in entry[\"files\"]]\n",
    "        if(\"custom_fields\" in entry.keys()):\n",
    "            md[\"citedBy\"] = getCited(entry)\n",
    "\n",
    "        return(md)\n",
    "    else:\n",
    "        print(f\"\\tReturned {resp.status_code} error for id {id}\")\n",
    "\n",
    "\n",
    "\n",
    "def standardizeType(type):\n",
    "    # standardizing to schema.org types\n",
    "    type_dict = {\n",
    "        \"dataset\": \"Dataset\",\n",
    "        \"journal contribution\": \"Publication\",\n",
    "        \"preprint\": \"Publication\",\n",
    "        \"figure\": \"ImageObject\",\n",
    "        \"online resource\": \"Website\",\n",
    "        \"media\": \"MediaObject\",\n",
    "        \"presentation\": \"PresentationDigitalDocument\",\n",
    "        \"poster\": \"CreativeWork\",\n",
    "        \"software\": \"SoftwareSourceCode\",\n",
    "        \"thesis\": \"Publication\",\n",
    "        \"book\": \"Publication\"\n",
    "    }\n",
    "    try:\n",
    "        return(type_dict[type])\n",
    "    except:\n",
    "        return(type.title())\n",
    "\n",
    "\n",
    "def standardizeDate(date_string, format=\"%Y-%m-%dT%H:%M:%S\", output_format=\"%Y-%m-%d\"):\n",
    "    try:\n",
    "        date_time = datetime.strptime(date_string, format)\n",
    "        return date_time.strftime(output_format)\n",
    "    except:\n",
    "        return(date_string)\n",
    "\n",
    "\n",
    "# TODO: within [\"custom_fields\"], for nih.figshare, there's more info about the funding within\n",
    "# \"Select an IC:\". However, it's not super obvious how to map the ICs into funding, because\n",
    "# both `Select an IC` and `funding_list` are arrays... should the names be zipped? copy multiple to each?\n",
    "# etc. Since as of now there are only 3 entries from NIH Figshare, delaying till later.\n",
    "# IDs: 12272015, 12026910, 12111570\n",
    "def getFunder(grant):\n",
    "    funding = {\"@type\": \"MonetaryGrant\"}\n",
    "    if((grant[\"grant_code\"] == grant[\"grant_code\"]) & (grant[\"grant_code\"] != \"\")):\n",
    "        funding[\"identifier\"] = grant[\"grant_code\"]\n",
    "    funding[\"description\"] = grant[\"title\"]\n",
    "    if((grant[\"funder_name\"] == grant[\"funder_name\"]) & (grant[\"funder_name\"] is not None)):\n",
    "        funding[\"funder\"] = [{\"@type\": \"Organization\",\n",
    "                             \"name\": grant[\"funder_name\"]}]\n",
    "    return(funding)\n",
    "\n",
    "\n",
    "def getCited(entry):\n",
    "    cited = []\n",
    "    names = [item[\"name\"] for item in entry[\"custom_fields\"]]\n",
    "    if(\"DOI(s) of associated publication(s):\" in names):\n",
    "        pubs = filter(lambda x: x[\"name\"] == \"DOI(s) of associated publication(s):\", entry[\"custom_fields\"])\n",
    "        for pubobj in pubs:\n",
    "            cited.extend([{\"@type\": \"Publication\", \"identifier\": pub.replace(\"https://doi.org/\", \"\"), \"doi\": pub.replace(\"https://doi.org/\", \"\"), \"url\": pub} for pub in pubobj[\"value\"]])\n",
    "    if(\"Published in\" in names):\n",
    "        citation = {\"@type\": \"Publication\"}\n",
    "        citation = getCustomValue(entry[\"custom_fields\"], citation, \"Published in\", \"journalName\")\n",
    "        citation = getCustomValue(entry[\"custom_fields\"], citation, \"Volume\", \"volumeNumber\")\n",
    "        citation = getCustomValue(entry[\"custom_fields\"], citation, \"Issue\", \"issueNumber\")\n",
    "        citation = getCustomValue(entry[\"custom_fields\"], citation, \"Pages\", \"pagination\")\n",
    "        citation = getCustomValue(entry[\"custom_fields\"], citation, \"Citation\", \"citation\")\n",
    "        citation = getCustomValue(entry[\"custom_fields\"], citation, \"Publication date\", \"datePublished\")\n",
    "        citation = getCustomValue(entry[\"custom_fields\"], citation, \"Acceptance date\", \"dateModified\")\n",
    "        citation = getCustomValue(entry[\"custom_fields\"], citation, \"DOI\", \"doi\")\n",
    "        cited.append(citation)\n",
    "    if(len(cited) > 0):\n",
    "        return(cited)\n",
    "\n",
    "def getCustomValue(arr, citation_obj, fieldname, new_name):\n",
    "    names = [item[\"name\"] for item in arr]\n",
    "    if(fieldname in names):\n",
    "        # Assumption: should only be one entry\n",
    "        filtered = filter(lambda x: x[\"name\"] == fieldname, arr)\n",
    "        try:\n",
    "            val = list(filtered)[0][\"value\"]\n",
    "            if(val != \"\"):\n",
    "                citation_obj[new_name] = val\n",
    "            return(citation_obj)\n",
    "        except:\n",
    "            return(citation_obj)\n",
    "\n",
    "# testing functions\n",
    "# cleanupFigshare(FIGSHARE_API, 12116301, 0, 1)\n",
    "# cleanupFigshare(FIGSHARE_API, 12111570, 0, 1)\n",
    "# x = getFigshare(ID_API, FIGSHARE_API, True) # Get a sample of the first five records\n",
    "# x = getFigshare(ID_API, FIGSHARE_API, False) # Get all Figshare records\n",
    "# import random\n",
    "# random.sample(x,1)\n",
    "\n",
    "\n",
    "def load_annotations():\n",
    "    path_dict = fetch_path_dict()\n",
    "    docs = getFigshare(ID_API, FIGSHARE_API)\n",
    "    for eachdoc in docs:\n",
    "        doc = add_anns(eachdoc)\n",
    "        yield doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched IDs 1 - 1000\n",
      "Fetched IDs 1001 - 2000\n",
      "Finished API call to get COVID-19 ID list\n",
      "finished 0 of 5\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "docs = getFigshare(ID_API, FIGSHARE_API, testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figshare13536282\n",
      "figshare12937019\n",
      "topicCategory in jdoc:  ['Public Health Interventions', ' Individual Prevention', ' Risk Factors', ' Clinical', ' Environment', ' Mechanism of Transmission', ' Transmission']\n",
      "figshare13077944\n",
      "topicCategory in jdoc:  ['Individual Prevention', ' Prevention']\n",
      "figshare12033672\n",
      "figshare12130980\n",
      "topicCategory in jdoc:  ['Behavioral Research']\n"
     ]
    }
   ],
   "source": [
    "path_dict = fetch_path_dict()\n",
    "for doc in docs:\n",
    "    jdoc = add_anns(path_dict,doc)\n",
    "    allfields = list(jdoc.keys())\n",
    "    print(jdoc['_id'])\n",
    "    if 'topicCategory' in allfields:\n",
    "        print(\"topicCategory in jdoc: \",jdoc['topicCategory'])\n",
    "    if 'correction' in allfields:\n",
    "        print(\"correction in jdoc: \",jdoc['correction'])\n",
    "    if 'evaluations' in allfields:\n",
    "        print(\"evaluations in jdoc: \",jdoc['evaluations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_dict = fetch_path_dict()\n",
    "#print(path_dict)\n",
    "for doc in docs[0:5]:\n",
    "    print(doc[\"_id\"])\n",
    "    ## add corrections\n",
    "    if doc['@type']=='Publication':\n",
    "        if 'pmid' in doc['_id']:\n",
    "            ## doc is from litcovid\n",
    "            corrections = fetch_annotation(path_dict,'litcovid_updates',doc['_id'])\n",
    "            loe_info = fetch_annotation(path_dict,'loe_annotations',doc['_id'])\n",
    "        else:\n",
    "            corrections = fetch_annotation(path_dict,'preprint_updates',doc['_id'])\n",
    "            loe_info = None\n",
    "        if corrections != None and len(corrections)>0:\n",
    "            if 'correction' in doc.keys():  ## check if correction field already used\n",
    "                try:\n",
    "                    doc['correction'].append(corrections)\n",
    "                except:\n",
    "                    correct_object = doc['correction']\n",
    "                    doc['correction']=[correct_object,corrections]\n",
    "            else:\n",
    "                doc['correction']=corrections\n",
    "        if loe_info != None and len(loe_info)>0:\n",
    "            print(\"LOE found\")\n",
    "            doc['evaluations'] = loe_info['evaluations']\n",
    "            if 'citedBy' in doc.keys():\n",
    "                doc['citedBy'].append(loe_info['citedBy'])\n",
    "            else:\n",
    "                doc['citedBy'] = []\n",
    "                doc['citedBy'].append(loe_info['citedBy'])\n",
    "    ## add topic_cats\n",
    "    topic_cats = fetch_annotation(path_dict,'topics_file',doc['_id'])\n",
    "    if topic_cats != None and len(topic_cats)>0:\n",
    "        doc['topicCategory']=topic_cats['topicCategory'].replace(\"'\",\"\").strip(\"[\").strip(\"]\").split(\",\")\n",
    "        print(doc['topicCategory'])\n",
    "    ## add altmetrics\n",
    "    altinfo = fetch_annotation(path_dict,'altmetrics_file',doc['_id'])\n",
    "    if altinfo != None and len(altinfo)>0:\n",
    "        print(\"altmetrics available, altinfo\")\n",
    "        if 'evaluations' in doc.keys():\n",
    "            try:\n",
    "                doc['evaluations'].append(altinfo['evaluations'][0])\n",
    "            except:\n",
    "                eval_object = doc['evaluations']\n",
    "                doc['evaluations']=[eval_object,altinfo['evaluations'][0]]\n",
    "        else:\n",
    "            doc['evaluations'] = altinfo['evaluations']       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
